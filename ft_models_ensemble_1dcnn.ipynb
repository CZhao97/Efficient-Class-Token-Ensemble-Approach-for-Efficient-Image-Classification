{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 313/313 [00:32<00:00,  9.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 313/313 [00:38<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 313/313 [00:38<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 313/313 [00:39<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.7082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 313/313 [00:39<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 313/313 [00:38<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 313/313 [00:39<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.5563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 313/313 [00:39<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 313/313 [00:39<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 313/313 [00:39<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.4923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 313/313 [00:37<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 313/313 [00:40<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.4668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 313/313 [00:40<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.4544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 313/313 [00:40<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 313/313 [00:40<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 313/313 [00:40<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.4267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 313/313 [00:40<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 313/313 [00:40<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.4140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 313/313 [00:40<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.4087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 313/313 [00:40<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.4012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 313/313 [00:40<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 0.3939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 313/313 [00:40<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 0.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 313/313 [00:40<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 313/313 [00:38<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 0.3826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 313/313 [00:43<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 0.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 313/313 [00:43<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 0.3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 313/313 [00:43<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 0.3759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 313/313 [00:43<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 0.3691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 313/313 [00:43<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 313/313 [00:43<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.3631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4086\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomHorizontalFlip, v2, Resize\n",
    "from tqdm import tqdm\n",
    "from accelerate import notebook_launcher\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import timm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "class lcnet_ft(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=1280):\n",
    "        super(lcnet_ft, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Load and freeze lcnet\n",
    "        self.encoder = timm.create_model('timm/lcnet_075.ra2_in1k', pretrained=True, num_classes=num_classes)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # unfreeze the last layer\n",
    "        for param in self.encoder.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.encoder(x)  # Assuming [batch_size, embed_dim]\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class mnasnet_ft(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=1280):\n",
    "        super(mnasnet_ft, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Load and freeze lcnet\n",
    "        self.encoder = timm.create_model('timm/mnasnet_small.lamb_in1k', pretrained=True, num_classes=num_classes)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # unfreeze the last layer\n",
    "        for param in self.encoder.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.encoder(x)  # Assuming [batch_size, embed_dim]\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class repghostnet_ft(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=1280):\n",
    "        super(repghostnet_ft, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Load and freeze lcnet\n",
    "        self.encoder = timm.create_model('timm/repghostnet_050.in1k', pretrained=True, num_classes=num_classes)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # unfreeze the last layer\n",
    "        for param in self.encoder.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.encoder(x)  # Assuming [batch_size, embed_dim]\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class ResNetViTEnsembleWithTransformer(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=1280):\n",
    "        super(ResNetViTEnsembleWithTransformer, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Load and freeze \n",
    "        self.lcnet = lcnet_ft(num_classes=num_classes, embed_dim=embed_dim)\n",
    "        self.mnasnet = mnasnet_ft(num_classes=num_classes, embed_dim=embed_dim)\n",
    "        self.repghostnet = repghostnet_ft(num_classes=num_classes, embed_dim=embed_dim)\n",
    "\n",
    "        self.lcnet.encoder.classifier = nn.Identity()\n",
    "        self.mnasnet.encoder.classifier = nn.Identity()\n",
    "        self.repghostnet.encoder.classifier = nn.Identity()\n",
    "\n",
    "        self.conv = nn.Conv1d(3, 1, kernel_size=3, stride=1, padding=1)  # 2 channels input\n",
    "\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get the features from the backbone\n",
    "        lcnet_features = self.lcnet.encoder(x)\n",
    "        mnasnet_features = self.mnasnet.encoder(x)\n",
    "        repghostnet_features = self.repghostnet.encoder(x)\n",
    "\n",
    "        feature_concat = torch.cat((lcnet_features.unsqueeze(1), mnasnet_features.unsqueeze(1), repghostnet_features.unsqueeze(1)), dim=1)\n",
    "        \n",
    "        feature_concat = self.conv(feature_concat).squeeze(1)\n",
    "\n",
    "        logits = self.classifier(feature_concat)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Assuming CIFAR10 - adapt transforms for your dataset\n",
    "transform = Compose([\n",
    "    Resize((224,224)),\n",
    "    RandomHorizontalFlip(),\n",
    "    # v2.ColorJitter(brightness=(0.5,1.5),contrast=(1),saturation=(0.5,1.5),hue=(-0.1,0.1)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]),\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader setup\n",
    "class FTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def train_model(train_loader, test_loader):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    model = ResNetViTEnsembleWithTransformer()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    model, optimizer, train_loader, test_loader = accelerator.prepare(model, optimizer, train_loader, test_loader)\n",
    "\n",
    "    for epoch in range(30):  # Adjust the number of epochs if needed\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Optional test phase at the end of training\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, labels in test_loader:\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    # Save the final model\n",
    "    model_path = \"/home/chen/EECE570/new_models/ensemble_model/model_final_1dcnn.pt\"\n",
    "    unencapsulated_model = accelerator.unwrap_model(model)\n",
    "    accelerator.save(unencapsulated_model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "def main():\n",
    "    root_dir = './data'\n",
    "    batch_size = 128\n",
    "    transform = Compose([\n",
    "        Resize((224,224)),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]),\n",
    "    ])\n",
    "    \n",
    "    # Load full dataset\n",
    "    full_dataset = CIFAR10(root=root_dir, train=True, download=True, transform=None)\n",
    "    images = [image for image, _ in full_dataset]\n",
    "    labels = [label for _, label in full_dataset]\n",
    "\n",
    "    # Stratified train-test split\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "        images, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "\n",
    "    # Creating datasets\n",
    "    train_dataset = FTDataset(train_images, train_labels, transform=transform)\n",
    "    test_dataset = FTDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # Call train_model or any other training function here\n",
    "    train_model(train_loader, test_loader)\n",
    "\n",
    "notebook_launcher(main, num_processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:10<00:00, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on testset\n",
    "model = ResNetViTEnsembleWithTransformer()\n",
    "model.load_state_dict(torch.load(\"/home/chen/EECE570/new_models/ensemble_model/model_final_1dcnn.pt\"))\n",
    "model.cuda()\n",
    "\n",
    "full_dataset = CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "images = [image for image, _ in full_dataset]\n",
    "labels = [label for _, label in full_dataset]\n",
    "\n",
    "\n",
    "testset = FTDataset(images, labels, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for x, labels in tqdm(testloader):\n",
    "    x, labels = x.cuda(), labels.cuda()\n",
    "    outputs = model(x)\n",
    "    predicted = torch.argmax(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy: {correct / total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
