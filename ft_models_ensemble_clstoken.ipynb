{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 313/313 [00:16<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 313/313 [00:16<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.3631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 313/313 [00:17<00:00, 18.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 313/313 [00:17<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 313/313 [00:17<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 313/313 [00:16<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 313/313 [00:17<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 313/313 [00:17<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.0493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 313/313 [00:17<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 313/313 [00:17<00:00, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.0378\n",
      "Time taken:  170.30673813819885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test time taken:  0.03673544111131113\n",
      "Epoch 10, Validation Loss: 0.5822\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from accelerate import Accelerator\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomHorizontalFlip, v2, Resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from accelerate import notebook_launcher\n",
    "import os\n",
    "import timm\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "class lcnet_ft(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=1280):\n",
    "        super(lcnet_ft, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Load and freeze lcnet\n",
    "        self.encoder = timm.create_model('timm/lcnet_075.ra2_in1k', pretrained=True, num_classes=num_classes)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # unfreeze the last layer\n",
    "        # for param in self.encoder.classifier.parameters():\n",
    "        #     param.requires_grad = True\n",
    "\n",
    "        self.linear = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.encoder(x)  # Assuming [batch_size, embed_dim]\n",
    "\n",
    "        # linear projection\n",
    "        # logits = self.linear(logits)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class mnasnet_ft(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=1280):\n",
    "        super(mnasnet_ft, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Load and freeze lcnet\n",
    "        self.encoder = timm.create_model('timm/mnasnet_small.lamb_in1k', pretrained=True, num_classes=num_classes)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # unfreeze the last layer\n",
    "        # for param in self.encoder.classifier.parameters():\n",
    "        #     param.requires_grad = True\n",
    "\n",
    "        self.linear = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.encoder(x)  # Assuming [batch_size, embed_dim]\n",
    "\n",
    "        # linear projection\n",
    "        # logits = self.linear(logits)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class repghostnet_ft(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=1280):\n",
    "        super(repghostnet_ft, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Load and freeze lcnet\n",
    "        self.encoder = timm.create_model('timm/repghostnet_050.in1k', pretrained=True, num_classes=num_classes)\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "        # unfreeze the last layer\n",
    "        # for param in self.encoder.classifier.parameters():\n",
    "        #     param.requires_grad = True\n",
    "\n",
    "        self.linear = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.encoder(x)  # Assuming [batch_size, embed_dim]\n",
    "\n",
    "        # linear projection\n",
    "        # logits = self.linear(logits)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n",
    "                FeedForward(dim, mlp_dim, dropout = dropout)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "class ResNetViTEnsembleWithTransformer(nn.Module):\n",
    "    def __init__(self, num_classes=10, embed_dim=1280, heads=12, dim_feedforward_hidden=768, num_layers=3, dropout=0):\n",
    "        super(ResNetViTEnsembleWithTransformer, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Load and freeze \n",
    "        self.lcnet = lcnet_ft(num_classes=num_classes, embed_dim=embed_dim)\n",
    "        self.mnasnet = mnasnet_ft(num_classes=num_classes, embed_dim=embed_dim)\n",
    "        self.repghostnet = repghostnet_ft(num_classes=num_classes, embed_dim=embed_dim)\n",
    "\n",
    "        self.lcnet.encoder.classifier = nn.Identity()\n",
    "        self.mnasnet.encoder.classifier = nn.Identity()\n",
    "        self.repghostnet.encoder.classifier = nn.Identity()\n",
    "\n",
    "        # Class token\n",
    "        self.class_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        nn.init.xavier_uniform_(self.class_token)\n",
    "        \n",
    "        # Transformer projection\n",
    "        # encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=heads, dim_feedforward=dim_feedforward_hidden, norm_first = False)    \n",
    "        # self.transformer_projection = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.transformer_projection = Transformer(embed_dim, num_layers, heads, dim_feedforward_hidden, dim_feedforward_hidden*4, dropout=dropout)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, num_classes),\n",
    "            # nn.ReLU(),\n",
    "            # # nn.Linear(4096, 2048),\n",
    "            # # nn.ReLU(),\n",
    "            # nn.Linear(512, 512),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get the features from the backbone\n",
    "        lcnet_features = self.lcnet.encoder(x)\n",
    "        mnasnet_features = self.mnasnet.encoder(x)\n",
    "        repghostnet_features = self.repghostnet.encoder(x)\n",
    "\n",
    "        # Concatenate class token with features\n",
    "        batch_size = x.size(0)\n",
    "        class_tokens = self.class_token.expand(batch_size, -1, -1)\n",
    "        combined_features = torch.cat((class_tokens, lcnet_features.unsqueeze(1), mnasnet_features.unsqueeze(1), repghostnet_features.unsqueeze(1)), dim=1)\n",
    "        combined_features = torch.cat((lcnet_features.unsqueeze(1), mnasnet_features.unsqueeze(1), repghostnet_features.unsqueeze(1)), dim=1)\n",
    "\n",
    "\n",
    "        # Pass through transformer projection\n",
    "        transformer_output = self.transformer_projection(combined_features)\n",
    "\n",
    "        # Use class token for classification\n",
    "        class_token_final = transformer_output[:, 0, :] \n",
    "\n",
    "        # class_token_final = transformer_output.mean(dim = 1)\n",
    "\n",
    "        # Final classification\n",
    "        logits = self.classifier(class_token_final)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Assuming CIFAR10 - adapt transforms for your dataset\n",
    "transform = Compose([\n",
    "    Resize((224,224)),\n",
    "    RandomHorizontalFlip(),\n",
    "    # v2.ColorJitter(brightness=(0.5,1.5),contrast=(1),saturation=(0.5,1.5),hue=(-0.1,0.1)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]),\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader setup\n",
    "class FTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def train_model(train_loader, test_loader):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    model = ResNetViTEnsembleWithTransformer()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    model, optimizer, train_loader, test_loader = accelerator.prepare(model, optimizer, train_loader, test_loader)\n",
    "\n",
    "    # time start\n",
    "    start = time.time()\n",
    "    for epoch in range(10):  # Adjust the number of epochs if needed\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, labels in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}\")\n",
    "    # time end\n",
    "    end = time.time()\n",
    "    print(\"Time taken: \", end-start)\n",
    "\n",
    "    # Optional test phase at the end of training\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        for x, labels in test_loader:\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "        end = time.time()\n",
    "        print(\"Test time taken: \", (end-start)/len(test_loader))\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Validation Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    # Save the final model\n",
    "    model_path = \"/home/chen/EECE570/new_models/ensemble_model/model_final_slctoken.pt\"\n",
    "    unencapsulated_model = accelerator.unwrap_model(model)\n",
    "    accelerator.save(unencapsulated_model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "def main():\n",
    "    root_dir = './data'\n",
    "    batch_size = 128\n",
    "    transform = Compose([\n",
    "        Resize((224,224)),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]),\n",
    "    ])\n",
    "    \n",
    "    # Load full dataset\n",
    "    full_dataset = CIFAR10(root=root_dir, train=True, download=True, transform=None)\n",
    "    images = [image for image, _ in full_dataset]\n",
    "    labels = [label for _, label in full_dataset]\n",
    "\n",
    "    # Stratified train-test split\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "        images, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "\n",
    "    # Creating datasets\n",
    "    train_dataset = FTDataset(train_images, train_labels, transform=transform)\n",
    "    test_dataset = FTDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # Call train_model or any other training function here\n",
    "    train_model(train_loader, test_loader)\n",
    "\n",
    "notebook_launcher(main, num_processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8665\n",
      "Recall: 0.9984\n",
      "Precision: 0.9994\n",
      "F1 Score: 0.9989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on testset\n",
    "model = ResNetViTEnsembleWithTransformer()\n",
    "model.load_state_dict(torch.load(\"/home/chen/EECE570/new_models/ensemble_model/model_final_slctoken.pt\"))\n",
    "model.cuda()\n",
    "\n",
    "full_dataset = CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "images = [image for image, _ in full_dataset]\n",
    "labels = [label for _, label in full_dataset]\n",
    "\n",
    "\n",
    "testset = FTDataset(images, labels, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "false = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "with torch.no_grad():\n",
    "    for x, labels in tqdm(testloader):\n",
    "        x, labels = x.cuda(), labels.cuda()\n",
    "        outputs = model(x)\n",
    "        predictions = torch.argmax(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        false_positive += ((predictions == 1) & (labels == 0)).sum().item()\n",
    "        false_negative += ((predictions == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "\n",
    "# output accuracy, recell, precision, f1 score\n",
    "accuracy = correct / total\n",
    "recall = correct / (correct + false_negative)\n",
    "precision = correct / (correct + false_positive)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
